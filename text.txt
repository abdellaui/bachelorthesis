




 


[1]m#1
#1


Pose Estimation in Gebäuden anhand von Convolutional Neural Networks und simulierten 3D-Daten
Abdullah Sahin
Bachelor
Angewandte Informatik
3. September 2019
108016202304
Prof. Dr.-Ing. Markus König
Patrick Herbers, M.Sc.

.....

spy,calc



0

/tikz/.cd,
	zoombox paths/.style=
	draw=orange,
	very thick
	,
	black and white/.is choice,
	black and white/.default=static,
	black and white/static/.style= 
	draw=white,   
	zoombox paths/.append style=
	draw=white,
	postaction=
	draw=black,
	loosely dashed
	
	
	,
	black and white/static/.code=
	1
	,
	black and white/cycle/.code=
		1
	,
	black and white pattern/.is choice,
	black and white pattern/0/.style=,
	black and white pattern/1/.style=    
	draw=white,
	postaction=
	draw=black,
	dash pattern=on 2pt off 2pt
	
	,
	black and white pattern/2/.style=    
	draw=white,
	postaction=
	draw=black,
	dash pattern=on 4pt off 4pt
	
	,
	black and white pattern/3/.style=    
	draw=white,
	postaction=
	draw=black,
	dash pattern=on 4pt off 4pt on 1pt off 4pt
	
	,
	black and white pattern/4/.style=    
	draw=white,
	postaction=
	draw=black,
	dash pattern=on 4pt off 2pt on 2 pt off 2pt on 2 pt off 2pt
	
	,
	zoomboxarray inner gap/.initial=5pt,
	zoomboxarray columns/.initial=2,
	zoomboxarray rows/.initial=2,
	subfigurename/.initial=,
	figurename/.initial=zoombox,
	zoomboxarray/.style=
	execute at begin picture=
	[
	spy using outlines=
	zoombox paths,
	width=/ /tikz/zoomboxarray columns - (/tikz/zoomboxarray columns - 1) / /tikz/zoomboxarray columns * /tikz/zoomboxarray inner gap -,
	height=/ /tikz/zoomboxarray rows - (/tikz/zoomboxarray rows - 1) / /tikz/zoomboxarray rows * /tikz/zoomboxarray inner gap-,
	magnification=3,
	every spy on node/.style=
	zoombox paths
	,
	every spy in node/.style=
	zoombox paths
	
	
	]
	,
	execute at end picture=
		at (image.north) [anchor=north,inner sep=0pt] ;
	at (zoomboxes container.north) [anchor=north,inner sep=0pt] ;
	0
	,
	spymargin/.initial=0.5em,
	zoomboxes xshift/.initial=1,
	zoomboxes right/.code=/tikz/zoomboxes xshift=1,
	zoomboxes left/.code=/tikz/zoomboxes xshift=-1,
	zoomboxes yshift/.initial=0,
	zoomboxes above/.code=
	/tikz/zoomboxes yshift=1,
	/tikz/zoomboxes xshift=0
	,
	zoomboxes below/.code=
	/tikz/zoomboxes yshift=-1,
	/tikz/zoomboxes xshift=0
	,
	caption margin/.initial=4ex,
	,
	adjust caption spacing/.code=,
	image container/.style=
	inner sep=0pt,
	at=(image.north),
	anchor=north,
	adjust caption spacing
	,
	zoomboxes container/.style=
	inner sep=0pt,
	at=(image.north),
	anchor=north,
	name=zoomboxes container,
	xshift=/tikz/zoomboxes xshift*(+/tikz/spymargin),
	yshift=/tikz/zoomboxes yshift*(+/tikz/spymargin+/tikz/caption margin),
	adjust caption spacing
	,
	calculate dimensions/.code=
	imagesouth west imagenorth east 
	
			1
	1
	1
	,
	image node/.style=
	inner sep=0pt,
	name=image,
	anchor=south west,
	append after command=
	[calculate dimensions]
	node [image container,subfigurename=/tikz/figurename-image] 
	node [zoomboxes container,subfigurename=/tikz/figurename-zoom] 
	
	,
	color code/.style=
	zoombox paths/.append style=draw=#1
	,
	connect zoomboxes/.style=
	spy connection path=[draw=none,zoombox paths] (tikzspyonnode) - (tikzspyinnode);
	,
	help grid code/.code=
	[
	x=(image.south east),
	y=(image.north west),
	font=,
	help lines,
	overlay
	]
	in 0,1,...,9  
	(/10,0) - (/10,1);
	[anchor=north] at (/10,0) 0.;
	
	in 0,1,...,9 
	(0,/10) - (1,/10);                        [anchor=east] at (0,/10) 0.;
	
	    
	,
	help grid/.style=
	append after command=
	[help grid code]
	
	,























Ergebnisse
 
Im vorliegenden Kapitel werden die Ergebnisse der durchgeführten Experimente präsentiert. Ein Evaluationsergebnis gibt in dieser Arbeit die Abweichung der Position in Metern und den Orientierungsfehler in Grad an. Ferner wird ein Evaluationsergebnis gegenüber Seinesgleichen anhand seines Positionsfehlers verglichen. Außerdem wird die Akkuratesse eines KNNs durch den Median aller Evaluationsergebnisse bestimmt. Im weiteren Verlauf dieses Kapitels werden zuerst die Reproduktionsergebnisse von BIM-PoseNet angegeben und danach die Evaluationsergebnisse der trainierten Netzwerke dargestellt.

Reproduktion der Ergebnisse von BIM-PoseNet
Die Ergebnisse der Experimente von (BIM-PoseNet), die das PoseNet Model mit den Gradientenbildern der karikaturistischen Daten (grad-cartoon) sowie synthetischen Kantenbilder trainierten (grad-edge) und anschließend mit den Gradientenbildern der realen Daten (grad-real) evaluierten, konnten näherungsweise reproduziert werden (vgl. Tab. ). Abweichend von BIM-PoseNet wurden statt 1000 grad-real Daten, 600 grad-real Daten evaluiert, weil zu derzeit 600 Evaluierungsbilder veröffentlicht waren. Der Trainingsprozess wurde pro Datensatztyp 5-mal wiederholt und die bessere Akkuratesse wurde behalten. Eine exakte oder bessere Reproduktion der Ergebnisse ist durch Zufall bedingt und wurde in dieser Arbeit aus Zeitgründen vernachlässigt. Tabelle  präsentiert die Ergebnisse der Reproduktion.



		Reproduktionsergebnisse. Abweichungen der Ergebnisse sind durch Zufall bedingt und können bei mehrfachem Wiederholen des Trainingsprozesses minimiert bzw. erhoben sowie verbessert werden. 
	1.0X X X
	Netzwerk  (Trainingsdatensatz) & BIM-PoseNet  (Position, Orientierung) & Reproduktion  (Position, Orientierung)

		 grad-cartoon & 2.63, 6.99° & 2.57, 10.52°

		grad-edge & 1.88, 7.73° & 2.53, 9.54°

		




Evaluation der trainierten KNNs
Für alle synthetischen Datensätze einer Strecke wurde das Trainingsprozess 5-mal mit den korrespondierenden Gradientenbildern der Trainingsdaten separat wiederholt. Eine Evaluation folgte mit den Gradientenbildern der korrespondierenden synthetischen Evaluationsdaten (Experiment 1). Eine weitere Evaluation der trainierten Netzwerke folgte mit den realen Evaluationsdaten der Strecke (Experiment 2). Es wurden pro Strecke je Datensatztyp nur die beste Akkuratesse behalten. Tabelle  bis  geben die Akkuratesse der KNNs auf den jeweiligen Strecken an. 

Für ein besseres Verständnis der durch die Evaluierung mit den grad-real Datensätzen resultierenden Akkuratesse wurden pro Strecke für die besten Netzwerke die bestimmten Positionen in der xy-Ebene dargestellt. Ebenso wurden pro Strecke die Positionsfehler in der xy-Ebene und die Orientierungsfehler auf der Gierachse der jeweiligen Evaluationsdaten dargestellt. Abbildungen  bis  illustrieren die Evaluationsergebnisse. Ferner wurde für die Akkuratesse als Referenzwert die bei der Bestimmung des Hyperparameters  ermittelten Akkuratessen festgelegt. Tabelle  gibt die Referenzwerte und die durchschnittlichen Ergebnisse der Experimente pro Strecke an.

IC-loop

In diesem Experiment wurde der IC-loop Datensatz verwendet. Eine durchschnittliche Akkuratesse von 1.80 in der Position und 8.05° in der Orientierung wurde mit den synthetischen Daten erzielt. Darüber hinaus ergab die Evaluation mit den realen Daten eine durchschnittliche Akkuratesse von 24.38, 61.24°. Eine Akkuratesse von 1.61, 8.17° wurde mit synthetischen Daten beim Trainieren und Evaluieren durch den grad-cartoon Datensatz erzielt. Bei der Evaluierung mit den Gradientenbildern der realen Evaluationsdaten wurde auf dem grad-photoreal Netzwerk eine Akkuratesse von 16.68, 73.25° erreicht (vgl. Tab. ). 

Das grad-photoreal Netzwerk bestimmte nur die Positionen aller grad-real Evaluationsdaten auf einem ca.  großen Teilbereich der unteren horizontalen Strecke (vgl. Abb. ). Daher wiesen Evaluationsdaten der kürzeren vertikalen sowie der obigen horizontalen Strecke die größten Positionsfehler auf (vgl. Abb. ). Ebenso bestimmte das Netzwerk größtenteils die Orientierung der Evaluationsdaten als die Aufnahmerichtung der unteren horizontalen Strecke (vgl. Abb. ).


		Evaluationsergebnisse von der Strecke IC-loop. Die Akkuratesse der mit den jeweiligen Trainingsdaten trainierten Netzwerken wird angegeben. Diese Netzwerke wurde mit den korrespondierenden synthetischen Evaluationsdaten und jeweils mit den realen Evaluationsdaten evaluiert.
	1.0X >X >X
	Trainingsdatensatz  (Gradientenbild) & synthetische Daten  (Position, Orientierung) & reale Daten  (Position, Orientierung)

		grad-cartoon & 1.61, 8.17° & 23.56, 51.30°

		grad-edge & 2.00, 8.29° & 32.91, 59.17°

		grad-photoreal & 1.80, 7.70° & 16.68, 73.25°

	===
	 Durchschnitt & 1.80, 8.05° & 24.38, 61.24°

		



	
0.9>p0.05 X
	  &   

	  &   

	  &   

		Visualisierung der Evaluationsergebnisse der Strecke IC-loop (s. Abb. ). Die Evaluation folgte mit den Gradietenbildern der realen Daten auf dem mit grad-photoreal trainierten Netzwerk. subfig:ic_fig2 illustriert die von dem KNN bestimmten Positionen auf der xy-Ebene. Der Positionsfehler in der xy-Ebene und der Orientierungsfehler auf der Gierachse der jeweiligen Evaluationsdaten werden in subfig:ic_fig4 und subfig:ic_fig6 dargestellt.
	

HS-gamma
Ein weiteres Experiment folgte mit dem HS-gamma Datensatz. Eine durchschnittliche Akkuratesse von 1.17 in der Position und 9.26° in der Orientierung wurde mit den synthetischen Daten erzielt. Darüber hinaus ergab die Evaluation mit den realen Daten eine durchschnittliche Akkuratesse von 9.67, 32.10°. Trainiert und evaluiert mit nur synthetischen Daten wurde durch den grad-cartoon Datensatz eine Akkuratesse von 1.00, 9.92° erzielt. Die Evaluierung mit den grad-real Evaluationsdaten auf dem grad-cartoon Netzwerk führte zur einer Akkuratesse von 8.60, 19.59° (vgl. Tab. ). 


Das grad-cartoon Netzwerk bestimmte überwiegend die Positionen aller grad-real Evaluationsdaten auf der linken horizontalen Strecke auf einem ca.  großen Teilbereich (vgl. Abb. ). Deshalb wiesen die Evaluationsdaten der linken horizontalen Strecke die geringsten Positionsfehler auf. Zudem zeigten die Evaluationsdaten des zum Ausgangspunkt optisch ähnlichen Flures die größten Positionsfehler auf (vgl. Abb. ). Ebenso bestimmte das oben erwähnte Netzwerk mehrheitlich die Orientierung der Evaluationsdaten als die Orientierung der dominierenden Aufnahmerichtung. Daher waren die größten Orientierungsfehler bei den Evaluationsdaten der Schlaufe sowie der vertikal verlaufenden Strecke aufzufinden (vgl. Abb. ). 



		Evaluationsergebnisse von der Strecke HS-gamma. Die Akkuratesse der mit den jeweiligen Trainingsdaten trainierten Netzwerken wird angegeben. Diese Netzwerke wurde mit den korrespondierenden synthetischen Evaluationsdaten und jeweils mit den realen Evaluationsdaten evaluiert.
	1.0X >X >X
	Netzwerk  (Trainingsdatensatz) & synthetische Daten  (Position, Orientierung) & reale Daten  (Position, Orientierung)

		grad-cartoon & 1.00, 9.92° & 8.60, 19.59°

		grad-edge & 1.07, 8.69° & 10.15, 35.11°

		grad-photoreal & 1.45, 9.17° & 10.27, 41.60°

	===
	 Durchschnitt & 1.17, 9.26° & 9.67, 32.10°

		

	
0.9>p0.05 X
	  &   

	  &   

	  &   

		Visualisierung der Evaluationsergebnisse der Strecke HS-gamma (s. Abb. ). Die Evaluation folgte mit den Gradietenbildern der realen Daten auf dem mit grad-cartoon trainierten Netzwerk. subfig:hs_gamma_fig2  illustriert die von dem KNN bestimmten Positionen auf der xy-Ebene. Der Positionsfehler der xy-Ebene und der Orientierungsfehler auf der Gierachse der jeweiligen Evaluationsdaten werden in subfig:hs_gamma_fig4 und subfig:hs_gamma_fig6 dargestellt.
	
HS-stairs-up

Weiterhin wurde ein Experiment mit dem HS-stairs-up Datensatz durchgeführt. Eine durchschnittliche Akkuratesse von 0.85 in der Position und 8.07° in der Orientierung wurde mit den synthetischen Daten erzielt. Darüber hinaus ergab die Evaluation mit den realen Daten eine durchschnittliche Akkuratesse von 4.75, 56.15°. Ausschließlich mit synthetischen Daten wurde eine Akkuratesse von 0.82, 7.76° durch die grad-cartoon Daten erzielt. Bei der Evaluierung mit den Gradientenbildern der realen Evaluationsdaten wurde eine Akkuratesse von 4.33, 51.64° durch das grad-edge Netzwerk erreicht (vgl. Tab. ). 

Die vom grad-edge Netzwerk bestimmten Positionen aller grad-real Evaluationsdaten liegen mehrheitlich zwischen dem unteren und oberen Treppenlauf (vgl. Abb. ). Deshalb waren die größten Positionsfehler bei den Evaluationsdaten des Treppenabsatzes aufzufinden. Ebenso waren bei den Evaluationsdaten des unteren und oberen Treppenlaufes abwechselnd größere Positionsfehler zu erkennen. Hierbei weisten die Evaluationsdaten des oberen Treppenlaufes häufiger einen größeren Positionsfehler auf (vgl. Abb. ). Die Orientierung der Evaluationsdaten des oberen Treppenlaufes wurden überwiegend als die Orientierung der Evaluationsdaten des unteren Treppenlaufes bestimmt. Ebenso waren bei den Evaluationsdaten der Treppenläufe abwechselnd in der entgegengesetzten Orientierung Fehler zu erkennen (vgl. Abb. ).


		Evaluationsergebnisse von der Strecke HS-stairs-up (s. Abb. ). Die Akkuratesse der mit den jeweiligen Trainingsdaten trainierten Netzwerken wird angegeben. Diese Netzwerke wurde mit den korrespondierenden synthetischen Evaluationsdaten und jeweils mit den realen Evaluationsdaten evaluiert.
	1.0X >X >X
	Netzwerk  (Trainingsdatensatz) & synthetische Daten  (Position, Orientierung) & reale Daten  (Position, Orientierung)

		grad-cartoon & 0.82, 7.76° & 4.77, 23.43°

		grad-edge & 0.82, 8.48° & 4.33, 51.64°

		grad-photoreal & 0.92, 7.98° & 5.16, 93.38°

	===
	 Durchschnitt & 0.85, 8.07° & 4.75, 56.15°

		


	
0.9>p0.05 X
	  &   

	  &   

	  &   

		Visualisierung der Evaluationsergebnisse der Strecke HS-stairs-up. Die Evaluation folgte mit den Gradietenbildern der realen Daten auf dem mit grad-edge trainierten Netzwerk. subfig:hs_up_fig3 illustriert die von dem KNN bestimmten Positionen auf der xy-Ebene. Der Positionsfehler in der xy-Ebene und der Orientierungsfehler auf der Gierachse der jeweiligen Evaluationsdaten werden in subfig:hs_up_fig5 und subfig:hs_up_fig7 dargestellt. 
	

HS-stairs-down



Zuletzt wurde ein Experiment mit dem HS-stairs-down Datensatz durchgeführt. Eine durchschnittliche Akkuratesse von 0.93 in der Position und 8.03° in der Orientierung wurde mit den synthetischen Daten erzielt. Darüber hinaus ergab die Evaluation mit den realen Daten eine durchschnittliche Akkuratesse von 5.01, 49.29°. Nur mit synthetischen Daten beim Trainieren und Evaluieren wurde eine Akkuratesse von 0.85, 7.50° durch die grad-edge Daten erzielt. Die Evaluierung mit den grad-real Evaluationsdaten auf dem mit grad-cartoon trainiertem Netzwerk führte zur einer Akkuratesse von 4.20, 47.83° (vgl. Tab. ). 

Das mit grad-cartoon trainierte Netzwerk bestimmte die Positionen aller grad-real Evaluationsdaten gleichermaßen wie im Unterabschnitt  zwischen dem unteren und oberen Treppenlauf (vgl. Abb. ). Deshalb waren hierbei genauso die größten Positionsfehler bei den Evaluationsdaten des Treppenabsatzes aufzufinden. Ebenso waren bei den Evaluationsdaten des unteren und oberen Treppenlaufes abwechselnd größere Positionsfehler zu erkennen. Diesmal wiesen die Evaluationsdaten des unteren Treppenlaufes häufiger einen größeren Positionsfehler auf (vgl. Abb. ). Im Vergleich zur HS-stairs-up  ist in der Abbildung  entlang der Treppenläufe eine stärkere Abwechslung der Orientierungsfehler zu erkennen.


		Evaluationsergebnisse von der Strecke HS-stairs-down (s. Abb. ). Die Akkuratesse der mit den jeweiligen Trainingsdaten trainierten Netzwerken wird angegeben. Diese Netzwerke wurde mit den korrespondierenden synthetischen Evaluationsdaten und jeweils mit den realen Evaluationsdaten evaluiert.
	1.0X >X >X
	Netzwerk  (Trainingsdatensatz) & synthetische Daten  (Position, Orientierung) & reale Daten  (Position, Orientierung)

		grad-cartoon & 0.91, 8.01° & 4.20, 47.83°

		grad-edge & 0.85, 7.50° & 5.59, 67.34°

		grad-photoreal & 1.02, 8.57° & 5.25, 32.70°

	===
	 Durchschnitt & 0.93, 8.03° & 5.01, 49.29°

		


	
0.9>p0.05 X
	  &   

	  &   

	  &   

		Visualisierung der Evaluationsergebnisse der Strecke HS-stairs-down. Die Evaluation folgte mit den Gradietenbildern der realen Daten auf dem mit grad-cartoon trainierten Netzwerk. subfig:hs_down_fig3  illustriert die von dem KNN bestimmten Positionen auf der xy-Ebene. Der Positionsfehler in der xy-Ebene und der Orientierungsfehler auf der Gierachse der jeweiligen Evaluationsdaten werden in subfig:hs_down_fig5 und subfig:hs_down_fig7 dargestellt.
	




		Zusammenfassung der Ergebnisse. Die Referenzwerte wurden während der Bestimmung des Hyperparameters  durch das Trainieren und Evaluieren mit den realen Daten ermittelt. Experiment 1 und 2 evaluieren die mit den Gradientenbildern der synthetischen Daten trainierten Netzwerke. Experiment 1 evaluiert mit den korrespondierenden Gradientenbildern der synthetischen Daten. Experiment 2 evaluiert mit den Gradientenbildern der realen Daten.
	1.0X >X >X >X
	Strecke & Referenzwert &  Experiment 1 &  Experiment 2 

		IC-loop & 1.93, 4.26° & 1.80, 8.05° & 24.38, 61.24°

		HS-gamma & 0.95, 7.53° & 1.17, 9.26° & 9.67, 32.10°

		HS-stairs-up & 0.94, 8.33° & 0.85, 8.07° & 4.75, 56.15°

		HS-stairs-down & 0.87, 9.25° & 0.93, 8.03° & 5.01, 49.29°

	====
	 Durchschnitt & 1.17, 7.34° & 1.19, 8.35° & 10.95, 49.69°

		



Diskussion








Die Ergebnisse der Untersuchungen haben gezeigt, dass der Ansatz von, worin das PoseNet mit Gradietenbilder der synthetischen Daten trainiert und mit Gradientenbildern der realen Daten evaluiert wird, ohne Optimierung der Hyperparameter auf die im Rahmen dieser Bachelorarbeit erhobenen Datensätze eine durchschnittliche Akkuratesse von 10.95 in der Position und 49.69° in der Orientierung erreichte. Die Evaluationen mit den synthetischen Gradientenbildern haben gezeigt, dass eine durchschnittliche Akkuratesse von 1.19, 8.35° mit synthetischen Daten übereinstimmend mit den Referenzwerten von 1.17, 7.34° erzielt werden kann.




In Gebäuden kommt es häufiger vor, dass unterschiedliche Stellen eines Innenraumes ähnliche Merkmale besitzen und somit schwer voneinander zu unterscheiden sind. Dieses Problem ist in der Literatur auch als perceptual-aliasing bekannt und stellt einen der größten Herausforderungen von Lokalisierungsverfahren dar. In dieser Arbeit wird diese Herausforderung durch das Anstreben einer domänenübergreifende Abstraktion bzw. das Erlenen von den Merkmalen der realen Daten aus den simulierten Daten zusätzlich verstärkt.


Die realen Evaluationsdaten auf den HS-stairs-down und HS-stairs-up Strecken wurden grundsätzlich zwischen der oberen und unteren Treppenlauf lokalisiert. Eine Generalisierungsfähigkeit zwischen Oben und Unten der KNNs ist nicht zuerkennen. Vielmehr ist eine zufällige Zuordnung der KNNs festzuhalten. Dies könnte aufgrund von wiederholenden Strukturen einer Treppen auf perceptual-aliasing zurückgeführt werden und würde die abwechselnde Fehlerrate auf den Evaluationsdaten der Treppenläufe erklären.

Außerdem haben die Ergebnisse der Strecken IC-loop und HS-gamma gezeigt, dass die realen Evaluationsdaten auf eine ca. 5 breiten und ca. 20 bis 30 langen Teilzone verteilt werden. Zusätzlich wurden die Orientierung der realen Evaluationsdaten als die Orientierung der von dem Anzahl der Trainingsdaten überwiegenden Richtung bestimmt. 


Die Ergebnisse von IC-loop und HS-gamma zeigen Parallele zu den Ergebnissen von, indem die von der Lokalisierung betroffenen Gebäudearealen eine vergleichbare Größe haben und die zu bestimmende Orientierung nur eine Richtung ist bzw. bestimmt wird.

Das Lokalisieren aller realen IC-loop Evaluationsdaten auf einem begrenzten Gebäudeareal könnte auf perceptual-aliasing zurückgeführt werden, da sich die Innenräume der vertikal sowie horizontal verlaufende Strecken optisch stark ähnelten. Im Gegensatz dazu waren in HS-gamma die Innenräume der vertikal und entlang der Schlaufe verlaufenden Strecken von den horizontalen Strecken optisch differenzierbar. Dennoch wurden in HS-gamma die realen Evaluationsdaten überwiegend auf einem Bereich der linken horizontalen Strecke lokalisiert. Obwohl einige Evaluationsdaten nahe der Schlaufe lokalisiert werden konnten, wurde dennoch die Orientierung als die Richtung der horizontalen Strecken bestimmt. Hierbei ist über perceptual-aliasing eine mögliche Erklärung der Ergebnisse nicht möglich.


acharyaBIMPoseNetIndoorCamera2019 stellten überraschend fest, dass die Akuratesse mit einem zunehmendem Level of Detail (LOD) der Gebäudesimulation (Trainingsdaten) bei der Evaluation mit den Gradientenbildern der realen Daten abnahm. Zeitgleich wird von den selben Autoren für eine bessere Akkuratesse ein hohes LOD empfohlen. Angesichts der Abnahme der Akkuratesse könnte das hohe LOD des HS-Gebäudesimulations für die unzureichende Akkuratesse bzw. Generalisierungsfähigkeit des KNNs auf den HS-Datensätzen eine mögliche Erklärung sein. Allerdings zeigte die Evaluation von der HS-gamma Strecke falsche Ergebnisse weit über eine vorstellbare Wirkung des LODs vor. Ebenso sollte nicht außer Acht gelassen werden, dass die Ergebnisse von HS-gamma Gemeinsamkeiten zu den Ergebnissen von IC-loop und der von vorzeigen.
















Die Gemeinsamkeiten der Ergebnisse scheinen jedoch fraglich, denn grundsätzlich ist PoseNet weder auf einen ca. 5 breiten und ca. 20 bis 30 langen Gebäudeareal noch für eine einzige Orientierung begrenzt. Zudem konnte in dieser Bachelorarbeit gezeigt werden, dass durch das Trainieren und Evaluieren mit den in dieser Arbeit erhobenen realen Datensätzen eine durchschnittliche Akkuratesse von 1.17, 7.34° und mit den synthetischen Datensätzen eine durchschnittliche Akkuratesse 1.19, 8.35° erzielt werden kann. Ferner konnten mit PoseNet durch das Trainieren und Evaluieren mit realen Daten in einem größeren Gebäudeareal als von den IC-loop oder HS-gamma Datensätzen mit einer Akkuratesse von 1.87, 6.14° die Pose bestimmen. Daher liegt angesichts der oben genannten Parallelen der Ergebnisse vielmehr die Erklärung der HS-gamma Ergebnisse bzw. die Schlussfolgerung nahe, dass PoseNet bei gleichen Hyperparametern wie in mit den Gradientenbildern der simulierte Daten für die Evaluation mit den Gradientenbildern der realen Daten auf einem begrenzten Gebäudeareal nur in einer Richtung trainiert werden kann.







 









Die Akkuratesse eines KNNs ist in dieser Arbeit durch den stochastischen Gradietenabstiegsverfahren AdaGrad bei der Optimierung des Losses im Trainingsprozess vom Zufall abhängig. Die durch den Zufall bedingten bestmöglichen Akkuratesse zu finden würde aus Zeitgründen den Rahmen dieser Bachelorarbeit sprengen. Weiterführende Forschungen können bei gleichen Hyperparametern die Anzahl der Trainingsprozesse erhöhen, um bessere Ergebnisse zu erzielen oder auszuschließen.


Weiterhin erzielten ihre besten Ergebnisse durch das Trainieren mit den Gradientenbilder der synthetischen Kantenbilder (grad-edge). In dieser Arbeit konnte eine bessere Akkuratesse mit den grad-cartoon Datensätzen häufiger erzielt werden. Dennoch kann auf dieser Tatsache kein Typ der synthetischen Daten als die Beste festgelegt werden, da zum nötigen Vergleich das Vorkommen der bestmöglichen Akkuratesse von jedem Datentyp weder sichergestellt noch ausgeschlossen werden kann. Weitere Forschungsprojekte können den Zusammenhang der Datentypen zu den Ergebnissen untersuchen.


Darüber hinaus behandelt diese Arbeit nicht die Optimierung der Hyperparameter. Die Hyperparameter wurden aus übernommen bzw. gleichermaßen bestimmt oder im selben Verhältnis zum Datensatz gewählt. Die Optimierung der Hyperparameter kann auf den jeweiligen Datensätzen zu besseren Ergebnissen führen und ist daher eine weitere Empfehlung für weiterführende Forschungen. 

Um das perceptual-aliasing Problem zu behandeln, wurde in der Literatur raumzeitliche Informationen aus Bildsequenzen von aufeinanderfolgenden Frames berücksichtigt. Des Weiteren wurde PoseNet an einem Bayessian Neural Network angepasst, um die Unsicherheit der Ergebnisse zu modellieren. Dadurch ist es in der Evaluationsphase möglich Ergebnisse zu vertrauen oder zu verwerfen. Angesichts dessen können weitere Forschungsprojekte die im Rahmen dieser Bachelorarbeit erhobenen Datensätze auf die Nachfolger von PoseNet anwenden und die Fähigkeit zur Lokalisierung untersuchen.


