% !TEX root = ../my_thesis.tex
\pagebreak
\section{Grundlagen}



% Lokalisierungsproblem erläutern
% Ansätze aufzählen
% Überführen auf visuelle Lokalisierung

% Arten erläutern
% indirekte methoden
% direkte methoden
% - point-matching
% - rgb-d
% - image only
% Überführen auf CNNs
\pagebreak
\textbf{Deep Convolutional Neural Networks} \textit{(DCNN)} werden erfolgreich im Bereich des Maschinelles Sehen, wie z. B. bei der Klassifizierung von Bildern \cite{krizhevskyImageNetClassificationDeep2012, simonyanVeryDeepConvolutional2014, heDeepResidualLearning2015} sowie bei der  Objekterkennung \cite{girshickRichFeatureHierarchies2013, renFasterRCNNRealTime2015b, girshickFastRCNN2015},  eingesetzt. 
Ein verbreiteter Ansatz beim Entwurf von DCNNs ist das häufig zweckentfremdende Feinabstimmung \textit{(fine-tune)} der Netzwerkarchitekturen, die z. B. für die Bildklassifizierung angesichts der Aufgaben von ImageNet \cite{russakovskyImageNetLargeScale2014} konstruiert wurden. Dieser Ansatz konnte beispielsweise erfolgreich in der Objekterkennung \cite{girshickFastRCNN2015}, Objektsegmentierung \cite{kokkinosPushingBoundariesBoundary2015, maninisConvolutionalOrientedBoundaries2016}, Semantische Segmentierung \cite{nohLearningDeconvolutionNetwork2015, hazirbasFuseNetIncorporatingDepth2017a} und Tiefenbestimmung \cite{liDepthSurfaceNormal2015} verfolgt werden.
Seit Kurzem werden DCNNs auch in den Anwendungsgebieten der Lokalisierung verwendet. Zum Beispiel verwenden \textit{Parisotto et al.} DCNNs in Bezug auf das SLAM Problem \cite{parisottoGlobalPoseEstimation2018}. \textit{Melekhov et al.} schätzen anhand DCNNs die relative Pose zweier Kameras \cite{melekhovRelativeCameraPose2017}. \textit{Constante et al.} und \textit{Wang et el.} setzen es im Bereich der visuellen Odometrie ein \cite{costanteExploringRepresentationLearning2016, wangDeepVOEndtoendVisual2017}.

% Posenet überführen
Geleitet von den state-of-the-art Lokalisierungsergebnissen der DCNNs stellen \textit{Kendall et al.} PoseNet \cite{kendallPoseNetConvolutionalNetwork2015} vor.
% Posenet erklären
PoseNet ist die Feinabstimmung der GoogLeNet \cite{szegedyGoingDeeperConvolutions2015} Architektur und zweckentfremdet es von der Bildklassifizierung zu einem Lokalisierungs-Regressor. Trainiert mit einem geringeren Datensatz bestehend aus Paaren von Farbbild und Pose, kann es die sechs Freiheitsgrade der Kameraposen in unbekannten Szenen bestimmen. Dieser Ansatz benötigt weder Tiefenbilder der Szene noch eine durchsuchbare Bildgalerie. Im Vergleich zu den metrischen Ansätzen wie SLAM oder visuelle Odometrie liefert es eine weniger akkurate Pose, jedoch bietet es eine hohe Toleranz gegenüber Skalierungs- und Erscheinungsänderungen des Anfragebildes an \cite{piascoSurveyVisualBasedLocalization2018}.


% Varianten aufzählen
Für die Verbesserung der Lokalisierung von PoseNet wurden viele Ansätze vorgestellt. Eine Erweiterung von PoseNet stellen die Autoren selbst


% Alternative CNNs regressors
Alternative 



% Simulierte Daten / syntethic

% Machine learning + syntethic

% 
