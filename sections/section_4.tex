% !TEX root = ../my_thesis.tex

\section{Ergebnisse}
Im vorliegenden Kapitel werden die Ergebnisse der durchgeführten Experimente präsentiert. Zuallererst werden die Ergebnisse von BIM-PoseNet \cite{acharyaBIMPoseNetIndoorCamera2019} reproduziert und angegeben, um die Korrektheit der Pipeline zu überprüfen. Anschließend wird der Hyperparameter $\beta$ der Kostenfunktion (vgl. Gleichung \ref{eq:posenet_loss}) für jeden realen Datensatz (siehe Abschnitt \ref{subsec:datasets}) bestimmt und angegeben. Mit der Bestimmung des Hyperparameters $\beta$ wird das neuronale Netz für jedes der synthetischen Datensätze mit den Gradientenbildern separat trainiert. Anschließend wird das neuronale Netz mit den korrespondieren Gradientenbilder der synthetischen sowie realen Daten evaluiert.

\subsection{Reproduktion der Ergebnisse von BIM-PoseNet}
Die Ergebnissen der Experimente von \citet{acharyaBIMPoseNetIndoorCamera2019}, die das PoseNet Model mit Gradientenbilder der karikaturistischen Daten sowie synthetischen Kantenbilder trainieren und anschließend mit den Gradientenbilder der realen Daten evaluieren, konnten näherungsweise (vgl. Tabelle \ref{tab:reproduction}) reproduziert werden. Eine exakte oder bessere Reproduktion der Ergebnisse ist durch Zufall bedingt und wird in dieser Arbeit aus Zeitgründen vernachlässigt.

Abweichend von BIM-PoseNet wurden statt 1000 reale Bilder, 600 reale Bilder evaluiert, weil derzeit 600 Evaluierungsbilder veröffentlicht sind. Die Mengenunterschiede der Evaluierungsdaten sind für die Endergebnisse trivial, da die Akkuratesse sich aus den Durchschnittswerten den Evaluationsergebnissen zusammensetzt und die Daten in zufälliger Reihe evaluiert werden. 

Der Trainingsprozess wurde je Datensatztyp zweimal wiederholt und die besseren Evaluationsergebnisse wurden behalten. Tabelle \ref{tab:reproduction} präsentiert die Ergebnisse der Reproduktion sowie die Ergebnisse der Autoren \citet{acharyaBIMPoseNetIndoorCamera2019}.


\begin{table}{b}
	\centering
	\caption{Reproduktionsergebnisse. Abweichungen der Ergebnisse sind durch Zufall bedingt und können bei mehrfachem Wiederholen des Trainingsprozesses minimiert bzw. erhoben sowie verbessert werden. }
	\begin{tabularx}{1.0\textwidth}{>{\hsize=1.2\hsize}X X X}
		\textbf{Trainingsdatensatz} \hspace{2cm} (Gradientenbild) & \textbf{BIM-PoseNet} \hspace{2cm} (Position, Orientierung) & \textbf{Reproduktion} \hspace{2cm} (Position, Orientierung)\\
		\hline
	 karikaturistische Simulation & 2.63$m$, 6.99° & 2.74$m$, 12.24°\\
		\hline
		synthetisches Kantenbild & 1.88$m$, 7.73°  & 2.53$m$, 9.54°\\
	\end{tabularx}
	\label{tab:reproduction}
\end{table}



\subsection{Bestimmung des Hyperparameters $\beta$}
\label{subsec:determine_beta}
gridsearch je datensatz mit realdaten, empfohlen 120-750 in gebäuden, in 9 schritten je 70 stride; plote beta ergebnisse matplotlib und evo traj-colormap

\cite{zhouLearningDeepFeatures2014} trainiert wurde. Anschließend werden die Gewichte an die Trainingsdaten angepasst. Tabelle \ref{tab:trainingparams} gibt eine Übersicht der Hyperparameter an.

\begin{table}[H]
	\centering
	\caption{Übersicht der Hyperparameter.}
	\begin{tabularx}{1.0\textwidth}{X X}
		\textbf{Hyperparameter} & \textbf{Wert}\\
		\hline
		Batchsize & $40$\\
		\hline
		Anzahl der Epochen & $160$\\
		\hline
		$\beta$ der Kostenfunktion (vgl. Gleichung \ref{eq:posenet_loss}) &
		siehe Tabelle \ref{tab:betas} im Abschnitt \ref{subsec:determine_beta}
		\\
		\hline
		Loss-Optimierer & AdaGrad\\
		\hline
		Lernrate & $10^{-3}$\\
		\hline
		Bildskalierung & $480 \times 270$\\
		\hline
		Bildausschnitt& \makecell[tl]{
			$224 \times 244$\\
			(Training: zufällig, Evaluation: zentriert)\\
		}\\
		\hline
		Datensatznormierung & Subtraktion des Durchschnittsbildes der synthetischen Daten \\
		\hline
		Initialisierung der Gewichte & Gewichte eines mit dem Places Datensatz trainierten Models auf GoogLeNet \\
	\end{tabularx}
	\label{tab:betas}
\end{table}

\subsubsection{IC-loop}
\subsubsection{HS-gamma}
\subsubsection{HS-stairs-up}
\subsubsection{HS-stairs-down}

\subsection{synth gradma vs synth gradma}
je evo traj-colormap
\subsubsection{IC-loop}
je blender point; edge hemi; cycl point
\subsubsection{HS-gamma}
je blender point; edge hemi; cycl point
\subsubsection{HS-stairs-up}
je blender point; edge hemi; cycl point
\subsubsection{HS-stairs-down}
je blender point; edge hemi; cycl point

\subsection{synth gradma vs real gradma}
je evo traj-colormap
\subsubsection{IC-loop}
je blender point; edge hemi; cycl point
\subsubsection{HS-gamma}
je blender point; edge hemi; cycl point
\subsubsection{HS-stairs-up}
je blender point; edge hemi; cycl point
\subsubsection{HS-stairs-down}
je blender point; edge hemi; cycl point
