% !TEX root = ../my_thesis.tex

\section{Einleitung}

Description of the problem to be solved with this work
• Objective of the work and the delivered contribution to science
• Structure of the work




In outdoor scenarios, the mobile terminal position
is obtained with high accuracy thanks to the global positioning
system (GPS) or to the standalone cellular systems. 

However, the
main problem of GPS and cellular systems resides in the indoor
environment and in scenarios with deep shadowing effects where
the satellite or cellular signals are broken.


In outdoor
scenarios, the UD position can be obtained with high accuracy
from Global Navigation Satellite Systems (GNSS), such as the
Global Positioning System (GPS), or from the standalone cellular systems. 

However, these positioning systems are severely
degraded or may fail altogether in indoor environments where
the satellite or cellular signals are interrupted, and in scenarios
with deep shadowing effects 
\cite{yassinRecentAdvancesIndoor2016}
%%%%%

The sensors of image based camera localization are cameras. 


There occur many 3D cameras
recently. This paper only considers 2D cameras. 


The usually used tool for localization is GPS
outdoors. However, GPS cannot be used indoors. 

There are many indoor localization tools
including Lidar, UWB, WiFi AP et al, among which using cameras to localization is the most
flexible and low cost one. 

Autonomous localization and navigation is necessary for a moving
robot. 


To augment reality on images, the camera pose or localization are needed. 

To view virtual
environments, the corresponding viewing angle is necessarily computed. 


Furthermore, cameras
are ubiquitous and people carry with their mobile phones that have cameras every day. 

Image
based camera localization has great and wide applications.
\cite{wuImageBasedCamera2016}


\subsection{Zeilsetzung}

Die Forscher \citet{acharyaBIMPoseNetIndoorCamera2019} konnten die Pose mit einer Akkuratesse von ca. $2m$ in der Position und 7° in der Orientierung auf einer ca. 18$m$ langen Strecke in einem ca. $20m \times 5m$ großen Korridor bestimmen (siehe Abb. \ref{fig:acharya_traj}). Dabei haben die Forscher entlang des Korridors reale Daten mit einem Smartphone erhoben und die korrespondierende Pose (\textit{Ground-Truth-Daten}) mit SfM-Methoden bestimmt. Daraufhin wurden unterschiedliche synthetische Daten entlang derselben Aufnahmestrecke in der 3D-Simulation des Korridors generiert, die sich in ihrer Realitätstreue vom Karikaturistischem zur fotorealistisch Texturiertem variieren. Anschließend wurde das PoseNet Modell (siehe Abschnitt \ref{sec:posenet}) mit Gradientenbilder der synthetischen Daten trainiert und mit Gradientenbilder der realen Daten evaluiert.
