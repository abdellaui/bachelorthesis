% !TEX root = ../my_thesis.tex

\section{Einleitung}
%
%Description of the problem to be solved with this work
%• Objective of the work and the delivered contribution to science
%• Structure of the work
%
%
%
%
%
%The usually used tool for localization is GPS
%outdoors. However, GPS cannot be used indoors. 
%
%There are many indoor localization tools
%including , UWB, WiFi AP et al, among which using cameras to localization is the most
%flexible and low cost one. 
%
%Autonomous localization and navigation is necessary for a moving
%robot. 
%
%
%To augment reality on images, the camera pose or localization are needed. 
%
%To view virtual
%environments, the corresponding viewing angle is necessarily computed. 
%
%
%Furthermore, cameras
%are ubiquitous and people carry with their mobile phones that have cameras every day. 
%
%Image
%based camera localization has great and wide applications.
%\cite{wuImageBasedCamera2016}




Die Bestimmung der Pose (\textit{Position + Orientierung}) von mobilen Geräten in Gebäuden verschafft im Bauwesen eine Reihe von Anwendungen wie z.B. die automatische Baufortschritterfassung sowie das Facility-Management und die Navigation über Augmented Reality \cite{kroppModelbasedPoseEstimation2016, kochNaturalMarkersAugmented2014}.
Während im Freien die mobilen Geräte über das \textit{Global Positioning System} (GPS) und die Mobilfunktechnologien lokalisiert werden können, ist grundsätzlich in Gebäuden und in der Abwesenheit von Satelliten- oder Funksignalen eine Lokalisierung über das GPS oder Mobilfunknetz nicht möglich \cite{yassinRecentAdvancesIndoor2016}. 

Für die Lokalisierung in Gebäuden gibt es verschiedene Verfahren, die sich an Technologien wie  \textit{LIDAR, Ultra-Breitband, Wireless Access Point, Bluetooth Beacon etc.} bedienen. Darin stellt die visuelle Lokalisierung über eine Kamera die kostengünstigste und flexibelste Alternative dar, weil es keine flächendeckenden Hardwareinstallationen benötigt. Dies ist dadurch bedingt, dass heutzutage viele Menschen ein Smartphone mit einer hochauflösenden Kamera bei sich führen \cite{wuImagebasedCameraLocalization2018}.

Visuelle Lokalisierungsansätze wie z.B. die 
\textit{visuelle Odemetrie} (VO) oder das \textit{Simultaneous-Localization-and-Mapping} (SLAM) sind eingeschränkt auf die lokale Positionbestimmung. Daher benötigen diese Ansätze eine Ausgangsposition des Sensors, um die absolute Position in einem Gebäude zu lokalisieren \cite{stephenseGlobalLocalizationUsing2002}. Dieses Problem ist in der Literatur auch als das \textit{Kidnapped-Robot-Problem} (KRP) bekannt. Das KRP beschäftigt sich mit einem von seiner Umpositionierung uninformierten (\textit{entführten}) Roboter. Dieser soll über die Sensormessungen eigenständig seine globale Position in der Umgebung lokalisieren.


Die absolute Lokalisierung eines visuellen Abfragematerials ist über das Suchen eines korrespondierenden Bildes in einer Bildergalerie oder über die Regression der Pose anhand von Bild-Features möglich \cite{piascoSurveyVisualBasedLocalization2018}. Diese Verfahren benötigen entweder eine Datenbank aus Bildern mit bekannten Posen \cite{zhangImageBasedLocalization2006, arandjelovicThreeThingsEveryone2012} oder zusätzliche Daten wie die 3D-Punktwolke \cite{irscharaStructurefrommotionPointClouds2009, liWorldwidePoseEstimation2012} oder Tiefenbilder der Szene \cite{shottonSceneCoordinateRegression2013}. Allerdings ist die Beschaffung der Bilder und zusätzlichen Daten von allen möglichen Posen im Gebäude zeit- und kostenaufwendig \cite{acharyaBIMPoseNetIndoorCamera2019}.


%Über Structure-from-Motion (\textit{SfM}) Methoden konnten 
%\citet{kendallPoseNetConvolutionalNetwork2015} trainierten mit Datensätzen bestehend aus einem Bild und die dazu korrespondierende Pose, die sie über Structure-from-Motion (\textit{SfM}) Methoden erhalten dem Sie Pose der 
% posenet kurz
%acharya
%ziele
%results
Hierfür versuchen die \textit{Pose Estimation} Ansätze wie z.B. PoseNet \cite{kendallPoseNetConvolutionalNetwork2015} mit \textit{künstlichen neuronalen Netzwerken} (KNN) eine geeignete Lösung zu bieten. PoseNet wird mit Datenpaaren bestehend aus RGB-Bildern und Posen trainiert, während die Ermittlung der Posen über das \textit{Structure-from-Motion} (SfM) einer Videoaufnahme der Umgebung genügt. Dennoch benötigen PoseNet und seine Nachfolger \cite{kendallModellingUncertaintyDeep2016, walchImageBasedLocalizationUsing2017, kendallGeometricLossFunctions2017, clarkVidLocDeepSpatioTemporal2017} Trainingsdaten durch das SfM der Videoaufnahmen, die den gesamten Innenraum der Gebäude abdecken. Die Aufnahme der Innenräume und das Erzeugen der Trainingsdaten über langsame und fehleranfällige SfM-Methoden ist zeitaufwändig und mühsam \cite{acharyaBIMPoseNetIndoorCamera2019}.

\citet{acharyaBIMPoseNetIndoorCamera2019} versuchten deshalb die Trainingsdaten aus der Simulation eines Gebäudes zu gewinnen. Dafür erzeugten die Forscher synthetische Bilder mit einer bekannten Pose entlang einer ca. 18$m$ langen Strecke in der 3D-Simulation eines Korridors. Trainiert auf dem PoseNet Modell mit den Gradientenbildern der synthetischen Daten konnten die Forscher \citet{acharyaBIMPoseNetIndoorCamera2019} bei der Evaluierung mit den Gradientenbildern der realen Daten eine Akkuratesse von ca. $2m$ in der Position und 7° in der Orientierung erzielen. Allerdings verlief die kurze Strecke überwiegend in einer Richtung sowie auf einer Etagenebene in der Simulation eines ca. $20m \times 5m \times 3m$ großen Korridors.


Ziel der vorliegenden Arbeit ist es, den Ansatz von \citet{acharyaBIMPoseNetIndoorCamera2019} in größeren Gebäudesimulationen und auf längeren Strecken, die einerseits in mehrere Richtungen verlaufen und andererseits sich auf mehreren Etagenebenen erstrecken, zu untersuchen. Um die Untersuchung bestmöglich an die Aufnahmestrecken und Gebäudesimulationen abhängig zu machen, wird möglichst gleichermaßen wie in \cite{acharyaBIMPoseNetIndoorCamera2019} reale Evaluationsdaten erhoben, synthetischen Trainingsdaten generiert und das PoseNet Modell mit übereinstimmenden Hyperparametern verwendet.

Folgendes konnte mit der vorliegenden Arbeit erreicht werden:
\begin{itemize}
	\item
	Insgesamt wurden vier Datensätze mit realen und synthetischen Daten aus den Innenräumen von zwei verschiedenen Gebäuden erhoben.
	\item 
	 Durch das Trainieren mit den Gradientenbildern der simulierten Daten von PoseNet konnte geschlussfolgert werden, dass die Gradientenbilder der realen Evaluationsdaten auf einem begrenzten Gebäudeareal nur in eine Richtung bestimmt werden können.
\end{itemize}





Im weiteren Verlauf dieser Arbeit wird in Kapitel \ref{sec:kapitel_2} einen Überblick des Forschungsstandes vermittelt und die Grundlagen von künstlichen neuronalen Netzwerken behandelt. Insbesondere wird auf \textit{Convolutional Neural Networks} eingegangen und die Netzwerkarchitektur von PoseNet vorgestellt, die in dieser Arbeit die Basis zur Untersuchung darstellt. Im Anschluss daran wird in Kapitel \ref{sec:kapitel_3} die Methodik dieser Arbeit wiedergegeben. Dort wird die Erhebung der Datensätze beschrieben und die Trainingsparameter der Untersuchungen angeben. Die Evaluationsergebnisse der trainierten KNNs werden in Kapitel \ref{sec:kapitel_4} präsentiert. Daraufhin werden über die Ergebnisse in Kapitel \ref{sec:kapitel_5} diskutiert. Abschließend wird in Kapitel \ref{sec:kapitel_6} ein Fazit gezogen. 


