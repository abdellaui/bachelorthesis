% !TEX root = ../my_thesis.tex

\section{Einleitung}
%
%Description of the problem to be solved with this work
%• Objective of the work and the delivered contribution to science
%• Structure of the work
%
%
%
%
%
%The usually used tool for localization is GPS
%outdoors. However, GPS cannot be used indoors. 
%
%There are many indoor localization tools
%including Lidar, UWB, WiFi AP et al, among which using cameras to localization is the most
%flexible and low cost one. 
%
%Autonomous localization and navigation is necessary for a moving
%robot. 
%
%
%To augment reality on images, the camera pose or localization are needed. 
%
%To view virtual
%environments, the corresponding viewing angle is necessarily computed. 
%
%
%Furthermore, cameras
%are ubiquitous and people carry with their mobile phones that have cameras every day. 
%
%Image
%based camera localization has great and wide applications.
%\cite{wuImageBasedCamera2016}




Die Bestimmung der Pose (\textit{Position + Orientierung}) von mobilen Geräten in Gebäuden verschafft im Bauwesen eine Reihe von Anwendungen wie z.B. automatische Baufortschritterfassung sowie Facility-Management und Navigation über Augmented Reality \cite{kroppModelbasedPoseEstimation2016, kochNaturalMarkersAugmented2014}.
Während im Freien mobile Geräte über Global Positioning System (\textit{GPS}) sowie Mobilfunktechnologien lokalisiert werden können, ist grundsätzlich in Gebäuden sowie in der Abwesenheit von Satelliten- oder Funksignalen eine Lokalisierung über GPS oder Mobilfunknetz nicht möglich \cite{yassinRecentAdvancesIndoor2016}. 

Für die Lokalisierung in Gebäuden gibt es verschiedene Verfahren, die sich an Technologien wie Lidar, Ultra-Breitband, Wireless Access Point, Bluetooth Beacon \textit{etc.} bedienen. Darin stellt die visuelle Lokalisierung über eine Kamera die kostengünstigste und flexibelste Alternative dar, weil es keine flächendeckende Hardwareinstallationen benötigt, da heutzutage viele Menschen ein Smartphone mit einer hochauflösenden Kamera bei sich führen \cite{wuImageBasedCamera2016}.

Visuelle Lokalisierungsansätzen wie z.B. 
visuelle Odemetrie (\textit{VO}) oder Simultaneous-Localization-and-Mapping (\textit{SLAM}) sind eingeschränkt auf die Bestimmung der lokalen Position und benötigen daher die Ausgangsposition des Sensors, um die absolute Position im Gebäude zu lokalisieren \cite{stephenseGlobalLocalizationUsing2002}. Dieses Problem ist in der Literatur auch als \textit{Kidnapped-Robot-Problem} (KRP) bekannt. KRP beschäftigt sich mit einem von seiner Umpositionierung uninformierten (\textit{entführten}) Roboter, der über Sensormessungen eigenständig seine globale Position in der Umgebung lokalisieren soll.


Die absolute Lokalisierung eines visuellen Abfragematerials ist über das Suchen eines korrespondierendes Bildes in einer Bildergalerie oder über die Regression der Pose anhand von Bild-Features möglich \cite{piascoSurveyVisualBasedLocalization2018}. Diese Verfahren benötigen entweder eine Datenbank aus Bildern mit bekannten Posen \cite{zhangImageBasedLocalization2006, arandjelovicThreeThingsEveryone2012, radenovicCNNImageRetrieval2016} oder zusätzliche Daten wie die 3D Punktwolke \cite{irscharaStructurefrommotionPointClouds2009, liWorldwidePoseEstimation2012, svarmCityScaleLocalizationCameras2017} oder Tiefenbilder der Szene \cite{shottonSceneCoordinateRegression2013a}. Allerdings ist die Beschaffung der Bilder und zusätzlichen Daten von allen möglichen Posen im Gebäude zeit- und kostenaufwendig.


%Über Structure-from-Motion (\textit{SfM}) Methoden konnten 
%\citet{kendallPoseNetConvolutionalNetwork2015} trainierten mit Datensätzen bestehend aus einem Bild und die dazu korrespondierende Pose, die sie über Structure-from-Motion (\textit{SfM}) Methoden erhalten dem Sie Pose der 
% posenet kurz
%acharya
%ziele
%results
Hierfür versuchen \textit{Pose Estimation} Ansätze mit künstlichen neuronalen Netzwerken wie z.B. PoseNet \cite{kendallPoseNetConvolutionalNetwork2015} eine geeignete Lösung zu bieten. PoseNet wird mit Datenpaaren bestehend aus RGB-Bildern und Pose trainiert, worin die Ermittlung der Posen über Structure-from-Motion (\textit{SfM}) einer Videoaufnahme der Umgebung genügt. PoseNet und seine Nachfolger \cite{kendallModellingUncertaintyDeep2015a, walchImagebasedLocalizationUsing2016,  kendallGeometricLossFunctions2017,  clarkVidLocDeepSpatioTemporal2017} benötigen über SfM der Videoaufnahmen erzeugten Trainingsdaten, die den gesamten Innenraum der Gebäude abdecken. Die Aufnahme der Innenräume und das Erzeugen der Daten über langsame und fehleranfällige SfM Methoden ist mühsam.

\citet{acharyaBIMPoseNetIndoorCamera2019} versuchten deshalb die Trainingsdaten aus der Simulation eines Gebäudes zu gewinnen. Die Forscher erzeugten synthetische Bilder mit korrespondierender Pose entlang einer ca. 18$m$ langen Strecke in der 3D-Simulation eines Korridors. Trainiert auf dem PoseNet Modell mit den Gradientenbildern der synthetischen Daten konnten die Forscher \citet{acharyaBIMPoseNetIndoorCamera2019} bei der Evaluierung mit den Gradientenbildern der realen Daten eine Akkuratesse von ca. $2m$ in der Position und 7° in der Orientierung erzielen. Allerdings verlief die \textit{kurze} Strecke überwiegend in einer Richtung sowie auf einer Etagenebene in der Simulation eines ca. $20m \times 5m$ großen Korridor.


Ziel der vorliegenden Arbeit ist es, den Ansatz von \citet{acharyaBIMPoseNetIndoorCamera2019} auf längeren Strecken, die einerseits in mehrere Richtungen verlaufen und andererseits sich auf mehreren Etagenebenen erstrecken, in größeren Gebäudesimulationen zu untersuchen. Um die Untersuchung best möglichst an die Aufnahmestrecken und Gebäudesimulationen abhängig zu machen, wird möglichst gleichermaßen wie in \cite{acharyaBIMPoseNetIndoorCamera2019} reale Evaluationsdaten erhoben, synthetischen Trainingsdaten generiert und das PoseNet Modell mit übereinstimmenden Hyperparametern verwendet.

Dieser Arbeit trägt Folgendes in die Forschung bei:
\begin{itemize}
	\item
	wird nach Diskussionsteil gefüllt
	\item
	placeholder
	\item
	placeholder
\end{itemize}

Im weiteren Verlauf dieser Arbeit wird in Kapitel \ref{sec:kapitel_2} einen Überblick des Forschungsstandes vermittelt und die Grundlagen von künstlichen neuronalen Netzwerken behandelt. Insbesondere wird auf Convolutional Neural Networks eingegangen und die Netzwerkarchitektur von PoseNet vorgestellt, die in dieser Arbeit die Basis zur Untersuchung darstellt. Im Anschluss daran wird in Kapitel \ref{sec:kapitel_3} die Methodik dieser Arbeit wiedergegeben. Dort wird die Erhebung der Datensätze beschrieben und die Trainingsparameter der Untersuchungen angeben. Die Evaluationsergebnisse der trainierten künstlichen neuronale Netzwerken werden in Kapitel \ref{sec:kapitel_4} präsentiert. Danach werden über die Ergebnisse in Kapitel \ref{sec:kapitel_5} diskutiert. Abschließend wird in Kapitel \ref{sec:kapitel_6} ein Fazit gezogen. 


