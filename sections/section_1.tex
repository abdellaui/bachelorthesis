% !TEX root = ../my_thesis.tex

\section{Einleitung}
%
%Description of the problem to be solved with this work
%• Objective of the work and the delivered contribution to science
%• Structure of the work
%
%
%
%
%
%The usually used tool for localization is GPS
%outdoors. However, GPS cannot be used indoors. 
%
%There are many indoor localization tools
%including Lidar, UWB, WiFi AP et al, among which using cameras to localization is the most
%flexible and low cost one. 
%
%Autonomous localization and navigation is necessary for a moving
%robot. 
%
%
%To augment reality on images, the camera pose or localization are needed. 
%
%To view virtual
%environments, the corresponding viewing angle is necessarily computed. 
%
%
%Furthermore, cameras
%are ubiquitous and people carry with their mobile phones that have cameras every day. 
%
%Image
%based camera localization has great and wide applications.
%\cite{wuImageBasedCamera2016}


%Simultaneous-Localization-and-Mapping (\textit{SLAM})
%visuelle Odemetrie (\textit{VO})
%Structure-from-Motion (\textit{SfM})
%Building-Information-Modeling (\textit{BIM})

Die Bestimmung der Pose (\textit{Position + Orientierung}) von mobilen Geräten in Gebäuden verschafft im Bauwesen eine Reihe von Anwendungen wie z.B. automatische Baufortschritterfassung sowie Facility-Management und Navigation über Augmented Reality \cite{kroppModelbasedPoseEstimation2016, kochNaturalMarkersAugmented2014}.
Während im Freien mobile Geräte über Global Positioning System (\textit{GPS}) sowie Mobilfunktechnologien lokalisiert werden können, ist grundsätzlich in Gebäuden sowie in der Abwesenheit von Satelliten- oder Funksignalen eine Lokalisierung über GPS oder Mobilfunknetz nicht möglich \cite{yassinRecentAdvancesIndoor2016}. 

Für die Lokalisierung in Gebäuden gibt es verschiedene Verfahren, die sich an Technologien wie Lidar, Ultra-Breitband, Wireless Access Points, Bluetooth Beacons etc. bedienen. Darin stellt die visuelle Lokalisierung über eine mobile Kamera die kostengünstigste und flexibelste Alternative dar, weil es keine flächendeckende Hardwareinstallationen benötigt, da heutzutage viele Menschen ein Smartphone mit einer hochauflösenden Kamera bei sich führen \cite{wuImageBasedCamera2016}.

Visuelle Lokalisierungsansätzen wie z.B. 
visuelle Odemetrie (\textit{VO}) oder Simultaneous-Localization-and-Mapping (\textit{SLAM}) sind eingeschränkt auf die Bestimmung der lokalen Position und benötigen daher die Ausgangsposition des Sensors, um die absolute Position im Gebäude zu lokalisieren \cite{stephenseGlobalLocalizationUsing2002}. Dieses Problem ist in der Literatur auch als \textit{Kidnapped-Robot-Problem} (KRP) bekannt. KRP beschäftigt sich mit einem von seiner Umpositionierung uninformierten (\textit{entführten}) Roboter, der über Sensormessungen eigenständig seine globale Position in einer Umgebung lokalisieren soll.


Die absolute Lokalisierung des visuellen Abfragemateriales ist über das Suchen eines korrespondierendes Bildes in einer Bildergalerie oder über die Regression der Pose anhand der Bild-Features möglich \cite{piascoSurveyVisualBasedLocalization2018}. Diese Verfahren benötigen entweder eine Datenbank aus Bildern mit bekannten Posen \cite{zhangImageBasedLocalization2006, arandjelovicThreeThingsEveryone2012, radenovicCNNImageRetrieval2016} oder zusätzlich Daten wie die 3D Punktwolke \cite{irscharaStructurefrommotionPointClouds2009, liWorldwidePoseEstimation2012, svarmCityScaleLocalizationCameras2017} oder Tiefenbilder der Szene \cite{shottonSceneCoordinateRegression2013a}. Allerdings ist die Beschaffung der Daten mit bekannter Pose bei großen Gebäuden zeit- und kostenaufwendig.

% posenet kurz
%acharya
%ziele
%was haben wir gemacht


%In Kapitel \ref{sec:kapitel_2} wird in den Stand der Forschung eingeführt und die Grundlagen von künstlichen neuronalen Netzwerken behandelt. Insbesondere wird auf Convolutional Neural Networks eingegangen und bekannte Netzwerkarchitekturen vorgestellt, die in dieser Arbeit die Basis zur Untersuchung darstellen. Im Anschluss daran wird in Kapitel \ref{sec:kapitel_3} die Methodik dieser Arbeit wiedergegeben. Dort wird die Erhebung der Datensätze beschrieben und die Trainingsparameter der Untersuchungen angeben. Die Evaluationsergebnisse der trainierten künstlichen neuronale Netzwerken werden in Kapitel \ref{sec:kapitel_4} präsentiert. Danach werden über die Ergebnisse in Kapitel \ref{sec:kapitel_5} diskutiert. Abschließend wird in Kapitel \ref{sec:kapitel_6} ein Fazit gezogen. 


