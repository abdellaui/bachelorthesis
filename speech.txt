Einleitung
~~~~~~~




***********************************************
***********************************************
***********************************************

Grundlagen
~~~~~~~




***********************************************
***********************************************
***********************************************

Methodik
~~~~~~~




***********************************************
***********************************************
***********************************************
Ergebnisse
~~~~~~~~~~



***********************************************
***********************************************
***********************************************

Diskussion
~~~~~~~~~~
Die Diskussion ist in 3 Abschnitte geteilt. 
Zuerst möchte ich die Defizite der angewandten Methodik auflisten, s.d. man diese im Hinterkopf behält.
Danach werden die Ergebnisse interpretiert und mit den Ergebnissen der Literatur verglichen.
Im Anschluss möchte ich noch Empfehlungen für weiterführende Forschungen geben.


D. der angewandten Methodik
~~~~~~~~~~~~~~~~~~~~~~~~~~~
Die in dieser Arbeit verwendetete Intel Realsense T265 versprach bei Bestkonditionen einen Drift von 1%.
wir konnten die Bestkonditionen nicht erfüllen s.d. eine  Abweichung bis zu 5% enstanden ist. Trotzdem 
konnte eine Korrespondenz der Ground-Truth-Daten zwischen der Erhobenen und von der Simulation verschafft werden.
Allerdings ist ein negativer Einfluss auf die Akkuratesse der domänenübergreifenden Evaluationen nicht auszuschließen bzw. denkbar.

Ein Weiterer Punkt ist, dass die Akkuratesse eines KNNS in dieser Arbeit durch das stochastische 
Gradientenabstiegsverfahren im Trainingsprozess vom Zufall abhängt. Die bestmögliche Akkuratesse zu finden würde den Rahmen
eines Bachelorarbeits sprengen. Deshalb wurden je Datentyp die Trainingsprozessse 5-mal wiederholt. Daher könnte bei
weiteren Trainingsprozesse bessere Ergebnisse erzielt werden.

Zudem wurden die Hyperparameter von Acharya et al übernommen und könnten auf deren Datensatz optimiert sein bzw.
mit deren Datensatz besser harmonieren. Infolgedessen könnten bei einer anderen Belegung der Hyperparameter ebenso
bessere Ergebnisse erziet werden.



D. der Ergebnisse
~~~~~~~~~~~~~~~~~~
In dieser Arbeit konnte auf die erhobenen Datensätze bei einer domänenübergreifende Evaluation eine durschnittliche
Akkuratesse von 10.95m, 49.69° erzielt werden. Ferner sollten die bei der Hyperparameterbestimmung erhaltenen 
Akkuratessen von 1.17m, 7.34° als Referenzwerte dienen. Dieses konnte die durch die Evaluationen mit Daten der gleichen 
Domäne mit 1.19m, 8.35° angenähert werden. Allerdings wure eine domänenübergreifende Ansatz gestrebt und diese ist bei 
den betroffenen Gebäuden mit einer Positionsakkuratesse von ca. 11m nicht denkbar

Bei den HS-stairs-down und up Strecken konnte keine Generalisierungsfähigkeit der Netzwerken erkannt werden, vielmehr
konnte eine zufällige Zuordnung interpretiert werden. Naja, so eine Treppe weist eben von Natur aus wiederholende Strukturen. 
Deshalb könnten die Unfähigkeiten der Netzwerke mit perceptual-aliasing begründet werden. 
Perceptual-aliasing ist eine der größten Herausforderungen visueller Lokalisierungsverfahren und wird 
in diesem Kontext als das optisch gleiche Erscheinen zweier verschiedenen Stellen eines Gebäudes definiert.

Weiterhin wurden die Evluationsdatend der Strecken IC-loop und HS-gamma in einem 
ca. 5m breiten und 20m bis 30m langen Teilbereich lokalisiert. Ebenso konnte man auch erkennen, dass 
die Netzwerke nur eine Richtung erlent haben. Während das Lokalisieren in einem Teilbereih bei der IC-Loop 
strecke auf perceptual-aliasing geführt werden könnte, da sowohl die vertikalen als auch die horizontalen Strecken
optisch gleich ausehen, unterscheiden die Evaluationsdaten der vertikalen und entlang der Schlaufe Strecke sich von den
horizontalen Strecken. Nichtdestotrotz wurden diese nur in einem Teilbereich der linken horizontalen Strecke lokalisiert.
Intressanterweise stellen diese Ergebnisse Parallelen zudem Datensatz bzw. Ergebnissen von Acharya et al. her.

Die schlechten Ergebnisse auf den HS Datensätzen könnten auf das hohe Level-of-Detail der Simulationen zurückgeführt werden,
da Achaya et al. überraschenderweise feststellten, dass die Zunahme des Level-of-Details zu einer Abnahme der Akkuratesse führte.
Widersprüchlicherweise empfehlten die Autoren für eine besseres Akkuratesse ein hohes Level-of-Detail der Simulationen. Naja, die 
Ergebnisse der HS-gamma Strecke waren weit über einem vorstellbaren Einfluss des hohen Level-of-Detail. Es sollte auch nicht außer
Acht gelassen werden, dass die Ergebnisse von HS-Gamma Gemeinsamkeiten zu den Ergebnissen von IC-loop und den Ergebnissen von Acharya aufweisen.

Was so eigentlich schon fraglich erscheint. PoseNet ist grundsätzlich nicht begrentz auf eine Teilzone von ca. 5m breite und 30m länge. In dieser Arbeit konnte mit Daten der gleichen
Domäne eine Positionsakkuratesse von ca. 1m erreicht werden. Ferner konnten Wlach et al. auf einen größeren Datensatz PoseNet erfolgreich anwenden.
Daher liegt die Schlussfolgerung nahe, dass PoseNet bei domänenübergreifende Anwendung nur in einem kleinen  Bereich in einer Richtung trainiert werden kann.


Empf. für weiterf. Forschungen
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Acharya et al. erzielten mit den edge-Datensätzen die besten Ergebnisse. In dieser Arbeit konnte mit den Gradientenbilder der cartoon-Datensätze häufiger besssere
Ergebnisse erzielt werden. Dennoch kann auf diesen Tatsachen kein bestes synth. Datentyp festgelegt werden, da hierzu die bestmögliche Akkuratessen nicht gewährleistet werden können, 
weil diese wie bereits erwähnt vom Zufall abhängig sind. Man könnte daher bei gleichen Hyperparametern die Anzahl der Trainigsprozesse erhöhen, um bessere Ergebnisse zu erzielen oder
auszuschließen. Infolgedessen könnte der Zusammenhang der Datentypen und Ergebnissen untersucht werden.

Wie Anfangs erwähnt wurden die Hyperparameter übernommen oder im gleichen Verhältnis bestimmt. Eine Optimierung der Hyperparameter sollte zu besseren Ergebnissen führen und
ist daher ebenso eine Empfehlung für weiterführende Forschung

Es gibt Nachfolger von PoseNet die das perceptual-aliasing Problem behandeln oder auch die Ungewissheit der Ergebnisse mitliefern, sodass man zum bestimmten Pose noch einen
Mass mitgeliefert bekommt, die angeben soll inwieweit man diesem Ergenissen vertrauen kann. Daher macht es Sinn die im Rahmen dieser Bachelorarbeit erhobenen Datensätze bei den Nachfolgern
anzuwenden.

***********************************************
***********************************************
***********************************************

Fazit
~~~~~~~
So, um jetzt alles nochmal abzurunden und abzuschließen. 
Ziel dieser Bachelorarbeit war es den Ansatz von Acharya in größeren Gebäuden auf längeren Strecken zu untersuchen. In wurde dieser Ansatz  mit 2 Gebäuden auf 4 Strecken untersucht. 
Zusammenfassend konnte festgestellt werden, dass eine Lokalisierungsverfahren durch eine domänenübergreifende Anwendung von PoseNet auf die hier erhobenen Datensätze nicht möglich gewesen
ist. Es konnte bei Daten der gleichen Domäne eine Akkuratesse von ca. 1m in der Position und 8° in der Orientierung erzielt werden. Bei der domänenübergreifenden Anwendung 
konnte eine Akkuratesse von 10.95m in der Position und 49.69° in der Orientierung erreicht werden. Hier konnte PoseNet nur in einem  Teilbereich und in einer Richtung trainiert werden. 
Angesichts der Parallen zu den Acharya et al. Datensätzen lag die Schlussfoglerung nahe, dass der Ansatz auf die erwähnten Eigenschaften begrentzt ist

Ein Lokalisierungsverfahren mit einer Positionsakkuratee von ca. 11m ist undenkbar. Soger die potenziell mögliche Akkuratesse von 1m wäre im direkten Gebrauch für z.B. Anwendungen
mit Augemented Reality nicht brauchbar, allerdings durch Kaskadeneffekt korriegierbar.

Jetz kommt so ein gröberer Ausblick zum domönenübergreifenden Anwendung..
Die Unzureichende Akkuratesse der domänenübergreifenden Evaluation liegt den Simulationsdefiziten wie das fehlen von Objekten oder domönenspezifsiche Artefakte wie z.B.
durch Licht oder Reflektieren von Gläsern etc zurück. Daher ist es lohnenswert in diesem Zusammenhang zu untersuchen, ob die Diskremepanzminimierung zwischen der
synth. Daten und der realen Daten z.B. durch GANS zu besseren Ergebnissen führt. Ferner könnte man die möglichen Posen im Trainingsprosses so einschränken, dass diese immer im begehbaren 
Flächen oder tatsächlich möglichen Bereichen liegen. Die dafür nötigen Informationen kann man ja durch die Simulation bzw. BIM der Gebäuden gewinnen.

